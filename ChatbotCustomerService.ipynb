{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ny0y/CustomerSupportChatbot/blob/main/ChatbotCustomerService.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yfsd52Y6SzvA",
        "outputId": "6a83f021-74f0-4969-f347-1c88a2ea8025"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec  4 08:13:46 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P8              15W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "id": "Yfsd52Y6SzvA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 1: Install Required Packages**"
      ],
      "metadata": {
        "id": "d9PomZUfQQvf"
      },
      "id": "d9PomZUfQQvf"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7b73275d-e74a-46a2-9b71-6f3f2bd67c8a",
      "metadata": {
        "id": "7b73275d-e74a-46a2-9b71-6f3f2bd67c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c97cb9-3303-4435-a41d-74027918214e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 2: Import Libraries**"
      ],
      "metadata": {
        "id": "Y_WRF9XhPw8P"
      },
      "id": "Y_WRF9XhPw8P"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e629b45-1d71-45cf-92f9-20adbcf3dd8c",
      "metadata": {
        "id": "7e629b45-1d71-45cf-92f9-20adbcf3dd8c"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 3: Load Dataset**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "57dU8JF1P2Me"
      },
      "id": "57dU8JF1P2Me"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "024fbce4-f79f-42a1-a6f4-826048e23767",
      "metadata": {
        "id": "024fbce4-f79f-42a1-a6f4-826048e23767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "462519ed-b9c6-4d11-b2a9-1569dda43055"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   flags                                        instruction category  \\\n",
              "0      B   question about cancelling order {{Order Number}}    ORDER   \n",
              "1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
              "2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
              "3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
              "4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
              "\n",
              "         intent                                           response  \n",
              "0  cancel_order  I've understood you have a question regarding ...  \n",
              "1  cancel_order  I've been informed that you have a question ab...  \n",
              "2  cancel_order  I can sense that you're seeking assistance wit...  \n",
              "3  cancel_order  I understood that you need assistance with can...  \n",
              "4  cancel_order  I'm sensitive to the fact that you're facing f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63d98641-bf28-4b26-87ca-6c791ac6bdae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flags</th>\n",
              "      <th>instruction</th>\n",
              "      <th>category</th>\n",
              "      <th>intent</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>question about cancelling order {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've understood you have a question regarding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BQZ</td>\n",
              "      <td>i have a question about cancelling oorder {{Or...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I've been informed that you have a question ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BLQZ</td>\n",
              "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I can sense that you're seeking assistance wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BL</td>\n",
              "      <td>I need to cancel purchase {{Order Number}}</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I understood that you need assistance with can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BCELN</td>\n",
              "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
              "      <td>ORDER</td>\n",
              "      <td>cancel_order</td>\n",
              "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63d98641-bf28-4b26-87ca-6c791ac6bdae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63d98641-bf28-4b26-87ca-6c791ac6bdae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63d98641-bf28-4b26-87ca-6c791ac6bdae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e10db781-48c4-4d9e-acf2-5adb1ed5d68a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e10db781-48c4-4d9e-acf2-5adb1ed5d68a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e10db781-48c4-4d9e-acf2-5adb1ed5d68a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 26872,\n  \"fields\": [\n    {\n      \"column\": \"flags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 394,\n        \"samples\": [\n          \"BCELNQ\",\n          \"BS\",\n          \"BCILNZ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24635,\n        \"samples\": [\n          \"I have an issue with the online registration\",\n          \"can you help me to open a standard account?\",\n          \"I want to locate order {{Order Number}}, could I get some help?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"REFUND\",\n          \"ORDER\",\n          \"DELIVERY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"contact_customer_service\",\n          \"delivery_period\",\n          \"contact_human_agent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26870,\n        \"samples\": [\n          \"Thank you for reaching out! I'm sorry to hear that you're facing difficulties in connecting with a human agent. Please rest assured that I'm here to assist you and resolve this issue. Could you please provide me with some more details about the problem you're experiencing? This will help me find the best solution for you.\",\n          \"I'll get right on it! I understand your need to locate the bills associated with {{Person Name}}. To assist you in finding the relevant invoices, could you please provide me with some additional details such as the date range or any other specific information that might help narrow down the search? Rest assured, I'm here to guide you every step of the way and ensure a seamless experience.\",\n          \"Definitely! I'm here to provide you with the necessary assistance in reporting any payment problems you are facing. Please share the specific details of the issue you're encountering, such as the nature of the problem, any error messages you've received, and any relevant transaction or account information. This will help us investigate and address the problem effectively. We appreciate your cooperation in bringing this matter to our attention, and we're committed to working together to find a solution.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset_path = '/content/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "data.head()  # Display first few rows for inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 4: Preprocess Data**"
      ],
      "metadata": {
        "id": "3muF33vTPsfO"
      },
      "id": "3muF33vTPsfO"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5dfaaaa1-ccdb-4143-b318-cf2c190d6284",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dfaaaa1-ccdb-4143-b318-cf2c190d6284",
        "outputId": "2e14746d-3f62-4c2b-b43e-da4c5378c594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Convert labels to integers (for BERT)\n",
        "data['intent'] = data['intent'].astype('category').cat.codes\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    data['instruction'], data['intent'], test_size=0.2, stratify=data['intent']\n",
        ")\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the data\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# Convert to PyTorch tensors and make sure labels are of type Long (int64)\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(train_encodings['input_ids']),\n",
        "    torch.tensor(train_encodings['attention_mask']),\n",
        "    torch.tensor(train_labels.values, dtype=torch.long)  # Make sure labels are of type Long\n",
        ")\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(test_encodings['input_ids']),\n",
        "    torch.tensor(test_encodings['attention_mask']),\n",
        "    torch.tensor(test_labels.values, dtype=torch.long)  # Make sure labels are of type Long\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 5: Create DataLoader for Training**"
      ],
      "metadata": {
        "id": "odzIbltcQ3ge"
      },
      "id": "odzIbltcQ3ge"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for training and testing\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "rqevjM6TQ8JW"
      },
      "id": "rqevjM6TQ8JW",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 6: Build the Model**"
      ],
      "metadata": {
        "id": "nE4yNZFbQ-8u"
      },
      "id": "nE4yNZFbQ-8u"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=27)\n",
        "\n",
        "# Step 1: Check if GPU is available and move model to the device\n",
        "device = torch.device('cuda')\n",
        "model = model.to(device)\n",
        "\n",
        "# Check the model device\n",
        "print(f\"Model is on device: {next(model.parameters()).device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z-Qs0PzRC2e",
        "outputId": "745bc9cb-6de8-4b95-d8fa-55a44210b646"
      },
      "id": "3Z-Qs0PzRC2e",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is on device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 7: Train the Model**"
      ],
      "metadata": {
        "id": "xcYGZozZRExe"
      },
      "id": "xcYGZozZRExe"
    },
    {
      "source": [
        "# Initialize loss function\n",
        "loss_fn = CrossEntropyLoss()\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5) # You can adjust the learning rate\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(3):  # You can change the number of epochs\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    for batch in tqdm(train_dataloader, desc=f\"\\nEpoch {epoch + 1}\"):\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(logits, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accuracy calculation\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        correct_predictions += (preds == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    print(f\"\\tLoss = {avg_loss:.4f}, Accuracy = {accuracy:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rend6iGggvx9",
        "outputId": "0644b837-301d-42a6-b517-2447bd57f134"
      },
      "id": "rend6iGggvx9",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 1:   0%|          | 0/672 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 1/672 [00:01<20:55,  1.87s/it]\n",
            "Epoch 1:   0%|          | 2/672 [00:02<09:57,  1.12it/s]\n",
            "Epoch 1:   0%|          | 3/672 [00:02<06:23,  1.74it/s]\n",
            "Epoch 1:   1%|          | 4/672 [00:02<04:43,  2.36it/s]\n",
            "Epoch 1:   1%|          | 5/672 [00:02<03:47,  2.93it/s]\n",
            "Epoch 1:   1%|          | 6/672 [00:02<03:13,  3.43it/s]\n",
            "Epoch 1:   1%|          | 7/672 [00:03<02:53,  3.84it/s]\n",
            "Epoch 1:   1%|          | 8/672 [00:03<02:40,  4.14it/s]\n",
            "Epoch 1:   1%|▏         | 9/672 [00:03<02:30,  4.41it/s]\n",
            "Epoch 1:   1%|▏         | 10/672 [00:03<02:24,  4.59it/s]\n",
            "Epoch 1:   2%|▏         | 11/672 [00:03<02:27,  4.49it/s]\n",
            "Epoch 1:   2%|▏         | 12/672 [00:04<02:23,  4.60it/s]\n",
            "Epoch 1:   2%|▏         | 13/672 [00:04<02:22,  4.62it/s]\n",
            "Epoch 1:   2%|▏         | 14/672 [00:04<02:17,  4.79it/s]\n",
            "Epoch 1:   2%|▏         | 15/672 [00:04<02:17,  4.76it/s]\n",
            "Epoch 1:   2%|▏         | 16/672 [00:04<02:15,  4.83it/s]\n",
            "Epoch 1:   3%|▎         | 17/672 [00:05<02:14,  4.85it/s]\n",
            "Epoch 1:   3%|▎         | 18/672 [00:05<02:15,  4.83it/s]\n",
            "Epoch 1:   3%|▎         | 19/672 [00:05<02:12,  4.94it/s]\n",
            "Epoch 1:   3%|▎         | 20/672 [00:05<02:12,  4.93it/s]\n",
            "Epoch 1:   3%|▎         | 21/672 [00:05<02:12,  4.93it/s]\n",
            "Epoch 1:   3%|▎         | 22/672 [00:06<02:11,  4.96it/s]\n",
            "Epoch 1:   3%|▎         | 23/672 [00:06<02:11,  4.93it/s]\n",
            "Epoch 1:   4%|▎         | 24/672 [00:06<02:09,  5.00it/s]\n",
            "Epoch 1:   4%|▎         | 25/672 [00:06<02:11,  4.93it/s]\n",
            "Epoch 1:   4%|▍         | 26/672 [00:06<02:15,  4.77it/s]\n",
            "Epoch 1:   4%|▍         | 27/672 [00:07<02:17,  4.68it/s]\n",
            "Epoch 1:   4%|▍         | 28/672 [00:07<02:17,  4.68it/s]\n",
            "Epoch 1:   4%|▍         | 29/672 [00:07<02:17,  4.69it/s]\n",
            "Epoch 1:   4%|▍         | 30/672 [00:07<02:15,  4.73it/s]\n",
            "Epoch 1:   5%|▍         | 31/672 [00:08<02:14,  4.77it/s]\n",
            "Epoch 1:   5%|▍         | 32/672 [00:08<02:13,  4.78it/s]\n",
            "Epoch 1:   5%|▍         | 33/672 [00:08<02:13,  4.78it/s]\n",
            "Epoch 1:   5%|▌         | 34/672 [00:08<02:13,  4.78it/s]\n",
            "Epoch 1:   5%|▌         | 35/672 [00:08<02:11,  4.84it/s]\n",
            "Epoch 1:   5%|▌         | 36/672 [00:09<02:15,  4.70it/s]\n",
            "Epoch 1:   6%|▌         | 37/672 [00:09<02:18,  4.57it/s]\n",
            "Epoch 1:   6%|▌         | 38/672 [00:09<02:27,  4.29it/s]\n",
            "Epoch 1:   6%|▌         | 39/672 [00:09<02:20,  4.49it/s]\n",
            "Epoch 1:   6%|▌         | 40/672 [00:09<02:16,  4.63it/s]\n",
            "Epoch 1:   6%|▌         | 41/672 [00:10<02:19,  4.54it/s]\n",
            "Epoch 1:   6%|▋         | 42/672 [00:10<02:16,  4.61it/s]\n",
            "Epoch 1:   6%|▋         | 43/672 [00:10<02:19,  4.51it/s]\n",
            "Epoch 1:   7%|▋         | 44/672 [00:10<02:15,  4.64it/s]\n",
            "Epoch 1:   7%|▋         | 45/672 [00:11<02:14,  4.65it/s]\n",
            "Epoch 1:   7%|▋         | 46/672 [00:11<02:14,  4.65it/s]\n",
            "Epoch 1:   7%|▋         | 47/672 [00:11<02:15,  4.60it/s]\n",
            "Epoch 1:   7%|▋         | 48/672 [00:11<02:19,  4.47it/s]\n",
            "Epoch 1:   7%|▋         | 49/672 [00:11<02:15,  4.58it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x7981b5441f50>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1196, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1290, in close\n",
            "    fp_write('')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1287, in fp_write\n",
            "    self.fp.write(str(s))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/utils.py\", line 196, in inner\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 402, in write\n",
            "    self.pub_thread.schedule(lambda : self._buffer.write(string))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\", line 203, in schedule\n",
            "    self._event_pipe.send(b'')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\", line 620, in send\n",
            "    return super().send(data, flags=flags, copy=copy, track=track)\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 746, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 793, in zmq.backend.cython.socket.Socket.send\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 243, in zmq.backend.cython.socket._send_copy\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d7abb7214d5b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Accuracy calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 8: Evaluate the Model**"
      ],
      "metadata": {
        "id": "d1ZCuzcGUzuu"
      },
      "id": "d1ZCuzcGUzuu"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables to calculate accuracy\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "# Disable gradient calculation for inference\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "        # Move batch to device\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Accuracy calculation\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        correct_predictions += (preds == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(f\"\\tTest Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "aG5RyZ9GU322"
      },
      "id": "aG5RyZ9GU322",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 9: Save and Load the Model**"
      ],
      "metadata": {
        "id": "htrdWQTHU7Z_"
      },
      "id": "htrdWQTHU7Z_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and tokenizer\n",
        "model.save_pretrained(\"/content/bert_chatbot_model\")\n",
        "tokenizer.save_pretrained(\"/content/bert_chatbot_model\")\n",
        "\n",
        "# Reload the model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(\"/content/bert_chatbot_model\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/bert_chatbot_model\")"
      ],
      "metadata": {
        "id": "sUK9pJViU_tW"
      },
      "id": "sUK9pJViU_tW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 10: Chatbot Inference**"
      ],
      "metadata": {
        "id": "3cHFpyp9VDQG"
      },
      "id": "3cHFpyp9VDQG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input text for inference\n",
        "text_input = \"How i do change my address\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(text_input, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "\n",
        "# Move input tensors to the same device as the model (GPU or CPU)\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Ensure the model is on the same device\n",
        "model.to(device)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():  # Disable gradients during inference\n",
        "    outputs = model(**inputs)  # Forward pass through the model\n",
        "    logits = outputs.logits  # Get the model's raw output (logits)\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()  # Get the predicted class index\n",
        "\n",
        "# Debugging: Print the predicted class index and available categories\n",
        "print(f\"Predicted class index: {predicted_class}\")\n",
        "\n",
        "# Get the number of intent classes\n",
        "num_classes = len(data['intent'].astype('category').cat.categories)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Define the intent_labels list (make sure this list has the correct number of categories)\n",
        "intent_labels = [\n",
        "    \"cancel_order\", \"change_order\", \"change_shipping_address\", \"check_cancellation_fee\",\n",
        "    \"check_invoice\", \"check_payment_methods\", \"check_refund_policy\", \"complaint\",\n",
        "    \"contact_customer_service\", \"contact_human_agent\", \"create_account\", \"delete_account\",\n",
        "    \"delivery_options\", \"delivery_period\", \"edit_account\", \"get_invoice\", \"get_refund\",\n",
        "    \"newsletter_subscription\", \"payment_issue\", \"place_order\", \"recover_password\",\n",
        "    \"registration_problems\", \"review\", \"set_up_shipping_address\", \"switch_account\",\n",
        "    \"track_order\", \"track_refund\"\n",
        "]\n",
        "\n",
        "# Ensure the list has the correct number of categories\n",
        "if len(intent_labels) == num_classes:\n",
        "    predicted_intent = intent_labels[predicted_class]\n",
        "    print(f\"Chatbot Response: {predicted_intent}\")\n",
        "else:\n",
        "    print(f\"Error: Mismatch between predicted class index and intent labels list size.\")\n"
      ],
      "metadata": {
        "id": "sOMD-Q5WjNdu"
      },
      "id": "sOMD-Q5WjNdu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 11 : confusion matrix**"
      ],
      "metadata": {
        "id": "dch9Yaz7azo2"
      },
      "id": "dch9Yaz7azo2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Get predictions\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=data['intent'].astype('category').cat.categories, yticklabels=data['intent'].astype('category').cat.categories)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QT5FkBU4VGk-"
      },
      "id": "QT5FkBU4VGk-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 12 : Test the classfication**"
      ],
      "metadata": {
        "id": "4PfZfoEQoONN"
      },
      "id": "4PfZfoEQoONN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample code for user input\n",
        "while True:\n",
        "    # Prompt the user for input\n",
        "    text_input = input(\"Please enter your message (type 'exit' to stop): \")\n",
        "\n",
        "    # Exit condition\n",
        "    if text_input.lower() == 'exit':\n",
        "        print(\"Exiting the chatbot.\")\n",
        "        break\n",
        "\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text_input, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    # Move input tensors to the same device as the model (GPU or CPU)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Ensure the model is on the same device\n",
        "    model.to(device)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():  # Disable gradients during inference\n",
        "        outputs = model(**inputs)  # Forward pass through the model\n",
        "        logits = outputs.logits  # Get the model's raw output (logits)\n",
        "        predicted_class = torch.argmax(logits, dim=1).item()  # Get the predicted class index\n",
        "\n",
        "    # Map the predicted class index to the corresponding intent label\n",
        "    predicted_intent = intent_labels[predicted_class]\n",
        "\n",
        "    # Print the chatbot's response (predicted intent)\n",
        "    print(f\"Chatbot Response: {predicted_intent}\")\n"
      ],
      "metadata": {
        "id": "rtKQ-Gv5mx_1"
      },
      "id": "rtKQ-Gv5mx_1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cell 13: Real-Time Interaction **"
      ],
      "metadata": {
        "id": "qoxC0w_doYkd"
      },
      "id": "qoxC0w_doYkd"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Real-time chatbot interaction\n",
        "while True:\n",
        "    # Prompt the user for input\n",
        "    text_input = input(\"\\nfCustomer: Please enter your message (type 'exit' to stop): \")\n",
        "\n",
        "    # Exit condition\n",
        "    if text_input.lower() == 'exit':\n",
        "        print(\"Exiting the chatbot. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text_input, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    # Move input tensors to the same device as the model (GPU or CPU)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():  # Disable gradients during inference\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # Map the predicted class index to the corresponding intent label\n",
        "    predicted_intent = intent_labels[predicted_class]\n",
        "\n",
        "    # Filter the dataset to get responses for the predicted intent\n",
        "    filtered_responses = df[df['intent'] == predicted_intent]['response'].tolist()\n",
        "\n",
        "    # Generate a random response from the filtered responses\n",
        "    if filtered_responses:\n",
        "        response = random.choice(filtered_responses)\n",
        "    else:\n",
        "        response = \"I'm sorry, I didn't understand your request. Can you please rephrase it?\"\n",
        "\n",
        "    # Output the chatbot's response\n",
        "    print(f\"Chatbot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "xw7UcqTLogid",
        "outputId": "3da8a6f1-a717-47bd-cb4b-e46e6a72cc99"
      },
      "id": "xw7UcqTLogid",
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "fCustomer: Please enter your message (type 'exit' to stop): fg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'intent_labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5e53cb8884ff>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Map the predicted class index to the corresponding intent label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mpredicted_intent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintent_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Filter the dataset to get responses for the predicted intent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'intent_labels' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}